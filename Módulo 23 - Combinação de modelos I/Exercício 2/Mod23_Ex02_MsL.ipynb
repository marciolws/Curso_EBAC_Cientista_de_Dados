{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![https://raw.githubusercontent.com/marciolws/Curso_EBAC_Cientista_de_Dados/refs/heads/main/EBAC-media-utils/logo/ebac_logo-data_science.png](https://raw.githubusercontent.com/marciolws/Curso_EBAC_Cientista_de_Dados/refs/heads/main/EBAC-media-utils/logo/ebac_logo-data_science.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- # **Profissão: Cientista de Dados** -->\n",
    "### **Módulo 23** | Combinação de modelos | Exercício II\n",
    "\n",
    "**Aluno:** [Marcio da Silva](https://www.linkedin.com/in/marciolws/)<br>\n",
    "**Data:** 02 de outubro de 2024.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tarefa II"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Monte um passo a passo para o algoritmo Random Forest:  \n",
    "\n",
    "> Com uma grande semelhança em relaçao ao Bagging, o **Random Forest** consiste em:\n",
    "> 1. **Bootstrap + Fature Selection**: Com sua grande semelhança ao Baggin, o RF utiliza amostas aleatórias com a reposiçao do conjunto de dados de treinamento original. Em cada uma dessas amostras, apenas um subconjunto aleatório de variáveis são selecionados (fature selection). Como encontramos problemas de classificaçao, é recomendado escolher a raiz quadrada do número total de variáveis, mas em problemas de regressão, um terço das variáveis é comumente usado.\n",
    "> 2. **Modelagem com árvores de decisão**: Aqui, um modelo de Marchine Leargning, uma árvore de decisão, é treinada de forma independente em cada amostra do bootstrap com as variaveis aleatórias que foram definidas anteriormente.\n",
    "> 3. **Agregação**: Nessa etapa final, os resultados de cada modelo intependente(ou seja, cada árvore de decisao) são agregados para obter uma previsão. Cas haja problemas de classificação, a agregaçao é feita por meio de um voto majoritário, ou seja, a classe prevista com mais frequência pelos modelos individuais é selecionada como classe final. Em regressão, essa agregação é feita calculadando a média das previsões dos modelos anteriores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Explique com suas palavras o Random Forest:\n",
    "\n",
    "> O algoritmo **Random Forest** é uma técnica de aprendizado de máquina que combina várias árvores de decisão para criar um modelo mais robusto e preciso. Ele é amplamente utilizado devido à sua eficácia na redução da variância, sua resistência ao overfitting e sua capacidade de lidar com uma variedade de problemas de aprendizado de máquina."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Qual a diferença entre Bagging e Random Forest?  \n",
    "\n",
    "> Embora **Bagging e Random Forest** sejam técnicas semelhantes, existem algumas diferenças importantes entre elas. A principal diferença está na forma como as árvores são construídas. No Bagging, cada árvore é construída usando o conjunto de dados completo, mas com amostras aleatórias com reposição. Já no Random Forest, cada árvore é construída usando um subconjunto aleatório de recursos para cada divisão. Essa diferença ajuda a aumentar a diversidade do ensemble no Random Forest e a reduzir a correlação entre as árvores individuais.  \n",
    "> Outra diferença está na forma como as previsões são combinadas. No Bagging, as previsões de cada modelo são combinadas por votação majoritária ou média. No Random Forest, as previsões de cada árvore são combinadas por votação majoritária. Essa diferença ocorre porque o Random Forest utiliza árvores de decisão como base, que são naturalmente classificadores binários."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. (Opcional) Implementar em python oo Random Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importando as bibiliotecas a serem usadas.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier()\n",
      "Accuracy score: 0.96\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_test</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    y_test  y_pred\n",
       "0        2       2\n",
       "1        2       1\n",
       "2        1       1\n",
       "3        2       2\n",
       "4        0       0\n",
       "5        0       0\n",
       "6        1       1\n",
       "7        2       2\n",
       "8        1       1\n",
       "9        2       2\n",
       "10       0       0\n",
       "11       1       1\n",
       "12       1       1\n",
       "13       1       1\n",
       "14       1       1\n",
       "15       0       0\n",
       "16       0       0\n",
       "17       0       0\n",
       "18       1       1\n",
       "19       2       2\n",
       "20       1       1\n",
       "21       2       2\n",
       "22       0       0\n",
       "23       1       1\n",
       "24       0       0\n",
       "25       1       1\n",
       "26       1       1\n",
       "27       2       2\n",
       "28       1       1\n",
       "29       0       0\n",
       "30       1       1\n",
       "31       1       1\n",
       "32       1       1\n",
       "33       0       0\n",
       "34       1       1\n",
       "35       0       0\n",
       "36       2       2\n",
       "37       2       2\n",
       "38       1       1\n",
       "39       0       0\n",
       "40       2       1\n",
       "41       2       2\n",
       "42       0       0\n",
       "43       2       2\n",
       "44       2       2\n",
       "45       0       0\n",
       "46       2       2\n",
       "47       1       1\n",
       "48       0       0\n",
       "49       2       2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Exemplo do Random Forest para problemas de classificaçao.\n",
    "\n",
    "x = load_iris().data\n",
    "y = load_iris().target\n",
    "\n",
    "df = pd.DataFrame(x, columns=load_iris().feature_names)\n",
    "df['target'] = y\n",
    "\n",
    "def rf_classifier(df:pd.DataFrame,\n",
    "                 num_bootstrap_samples:int=3, #Parametro da funçao que define quantidade de amostragens para o treinamento.\n",
    "                 test_size:float=0.26\n",
    "                 ) -> pd.DataFrame:\n",
    "    df_train, df_test = train_test_split(df, test_size=test_size)\n",
    "\n",
    "    x_test = df_test.drop(['target'], axis=1)\n",
    "    y_test = df_test['target'].rename('y_test')\n",
    "\n",
    "    #Dicionário para os resultados das predições de cada modelo.\n",
    "    y_pred_bagging = {}\n",
    "\n",
    "    for i in range(num_bootstrap_samples):\n",
    "        #bootstrap\n",
    "        df_train = df_train.sample(n=len(df_train),\n",
    "                                   replace=True) #Amostragem com reposição.\n",
    "        \n",
    "        x_train = df_train.drop(['target'], axis=1)\n",
    "        y_train = df_train.sample(n=round(np.sqrt(x_train.shape[1])), # Calculo da raix quadrada da quantidade de variaveis.\n",
    "                                  axis=1)\n",
    "        y_train = df_train['target']\n",
    "        #Modelagem - base learners.\n",
    "        model = DecisionTreeClassifier()\n",
    "        model.fit(x_train, y_train)\n",
    "\n",
    "        #Adicionando os resultados do modelo ao dicionário para agregação das predições.\n",
    "        y_pred_bagging.update({i:model.predict(x_test[x_train.columns])})\n",
    "\n",
    "    #Agregating.\n",
    "    y_pred = (pd.DataFrame(y_pred_bagging)\n",
    "              .mode(axis=1) #Aqui agraga o valor com o maior numero de aparições nas predições dos modelos.\n",
    "              .rename(columns={0:'y_pred'}))\n",
    "    \n",
    "    #Resultados obtidos.\n",
    "    print(model)\n",
    "    print('Accuracy score:', accuracy_score(y_true=y_test,\n",
    "                                            y_pred=y_pred['y_pred']\n",
    "                                            ))\n",
    "    \n",
    "    return pd.concat(objs = [y_test.reset_index(drop=True),\n",
    "                             y_pred['y_pred'].astype(int)],\n",
    "                             axis=1)\n",
    "\n",
    "rf_classifier(num_bootstrap_samples=10, df=df, test_size=0.33)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeRegressor()\n",
      "Mean squared error: 14637.616438356165\n",
      "Coefficient of determination: -1.377759627935602\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_test</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>288.0</td>\n",
       "      <td>310.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>292.0</td>\n",
       "      <td>310.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>252.0</td>\n",
       "      <td>104.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>96.0</td>\n",
       "      <td>310.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>109.0</td>\n",
       "      <td>198.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>272.0</td>\n",
       "      <td>317.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>202.0</td>\n",
       "      <td>310.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>268.0</td>\n",
       "      <td>174.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>116.0</td>\n",
       "      <td>104.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>78.0</td>\n",
       "      <td>104.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>146 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     y_test  y_pred\n",
       "0     288.0   310.0\n",
       "1     292.0   310.0\n",
       "2     252.0   104.0\n",
       "3      96.0   310.0\n",
       "4     109.0   198.0\n",
       "..      ...     ...\n",
       "141   272.0   317.0\n",
       "142   202.0   310.0\n",
       "143   268.0   174.0\n",
       "144   116.0   104.0\n",
       "145    78.0   104.0\n",
       "\n",
       "[146 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Exemplo do Random Forest para problemas de regressão.\n",
    "\n",
    "x = load_diabetes().data\n",
    "y = load_diabetes().target\n",
    "\n",
    "df = pd.DataFrame(x, columns=load_diabetes().feature_names)\n",
    "df['target'] = y\n",
    "\n",
    "def rf_regressor(df:pd.DataFrame,\n",
    "                 num_bootstrap_samples:int=3,  #Parametro da funçao que define quantidade de amostragens para o treinamento.\n",
    "                 test_size:float=0.25\n",
    "                 ) -> pd.DataFrame:\n",
    "    \n",
    "    df_train, df_test = train_test_split(df, test_size=test_size)\n",
    "\n",
    "    x_test = df_test.drop(['target'], axis=1)\n",
    "    y_test = df_test['target'].rename('y_test')\n",
    "\n",
    "    #Dicionário para resultados das predições de cada modelo.\n",
    "    y_pred_bagging = {}\n",
    "\n",
    "    for i in range(num_bootstrap_samples):\n",
    "        #Bootstrap\n",
    "        df_train = df_train.sample(n=len(df_train),\n",
    "                                   replace=True) #Amostragem com reposição.\n",
    "        \n",
    "        x_train = df_train.drop(['target'], axis=1)\n",
    "        #Fature selection\n",
    "        x_train = x_train.sample(n=round(x_train.shape[1]/3),\n",
    "                                 axis=1) #Calculo da quantidade de variaveis dividido por 3.\n",
    "        \n",
    "        y_train = df_train['target']\n",
    "\n",
    "        #Modelagem, base learners.\n",
    "        model = DecisionTreeRegressor()\n",
    "        model.fit(x_train, y_train)\n",
    "\n",
    "        #Adicionando os resultados do modelo a um dicionario para agragaçao das predições.\n",
    "    y_pred_bagging.update({i:model.predict(x_test[x_train.columns])})\n",
    "        \n",
    "    #Agregating\n",
    "    y_pred = (pd.DataFrame(y_pred_bagging)\n",
    "                  .mean(axis=1)\n",
    "                  .rename('y_pred'))\n",
    "        \n",
    "    #Printando os resultados.\n",
    "    print(model)\n",
    "    print('Mean squared error:', mean_squared_error(y_true=y_test,\n",
    "                                                        y_pred=y_pred))\n",
    "    print('Coefficient of determination:', r2_score(y_true=y_test,\n",
    "                                                        y_pred=y_pred))\n",
    "        \n",
    "    return pd.concat(objs=[y_test.reset_index(drop=True),\n",
    "                               y_pred],\n",
    "                               axis=1)\n",
    "\n",
    "rf_regressor(num_bootstrap_samples=100, df=df, test_size=0.33)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Índice",
   "title_sidebar": "Conteúdo",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
